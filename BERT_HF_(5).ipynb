{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT_HF (5).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OcRl5qE4faCi",
        "q5jC99D79xAg",
        "EOs8pOTD-FPw",
        "DOk49lL9Bc8R"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbejarano31/Master-Thesis-Information-Management/blob/main/BERT_HF_(5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0Jq91Hw85wK"
      },
      "source": [
        "# BERT\n",
        "<br> </br>\n",
        "\n",
        "Here we are going to try another implementation of BERT, using the HuggingFace API [see here](https://huggingface.co/transformers/main_classes/trainer.html).\n",
        "<br></br>\n",
        "To download our dataset, [see here](https://drive.google.com/file/d/1o1BMTTU9YNPATL8x93l0N-h6sTZxLyDo/view?usp=sharing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcRl5qE4faCi"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKzSfOr3FV0e",
        "outputId": "3276a5f9-f3f6-4ff5-e932-771724d3b475"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-utsvydsl\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-utsvydsl\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied (use --upgrade to upgrade): transformers==4.6.0.dev0 from git+https://github.com/huggingface/transformers in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0.dev0) (0.10.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0.dev0) (3.4.1)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.6.0.dev0-cp37-none-any.whl size=2178482 sha256=615f457aad392146f0c2d5a0f1b3e9926ad815d268d23ba1b479f348fcf69fcb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-umbta3wc/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "Successfully built transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQIaevyCQDZj",
        "outputId": "3b40fdce-599a-4fda-e42b-6be9705b5ae8"
      },
      "source": [
        "#!pip install transformers\n",
        "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "\n",
        "from transformers.utils import *\n",
        "from transformers.data.data_collator import DataCollator, DataCollatorWithPadding, default_data_collator\n",
        "from transformers.file_utils import (\n",
        "    WEIGHTS_NAME,\n",
        "    is_apex_available,\n",
        "    is_datasets_available,\n",
        "    is_in_notebook,\n",
        "    is_sagemaker_dp_enabled,\n",
        "    is_sagemaker_mp_enabled,\n",
        "    is_torch_tpu_available,\n",
        "    is_training_run_on_sagemaker,\n",
        ")\n",
        "from transformers.modeling_utils import PreTrainedModel, unwrap_model\n",
        "from transformers.optimization import Adafactor, AdamW, get_scheduler\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
        "from transformers.trainer_callback import (\n",
        "    CallbackHandler,\n",
        "    DefaultFlowCallback,\n",
        "    PrinterCallback,\n",
        "    ProgressCallback,\n",
        "    TrainerCallback,\n",
        "    TrainerControl,\n",
        "    TrainerState,\n",
        ")\n",
        "from transformers.trainer_utils import (\n",
        "    PREFIX_CHECKPOINT_DIR,\n",
        "    BestRun,\n",
        "    EvalPrediction,\n",
        "    HPSearchBackend,\n",
        "    PredictionOutput,\n",
        "    ShardedDDPOption,\n",
        "    TrainerMemoryTracker,\n",
        "    TrainOutput,\n",
        "    default_compute_objective,\n",
        "    default_hp_space,\n",
        "    denumpify_detensorize,\n",
        "    get_last_checkpoint,\n",
        "    set_seed,\n",
        "    speed_metrics,\n",
        ")\n",
        "from transformers.training_args import ParallelMode, TrainingArguments\n",
        "from transformers.utils import logging\n",
        "from transformers.utils.modeling_auto_mapping import MODEL_FOR_QUESTION_ANSWERING_MAPPING_NAMES \n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5jC99D79xAg"
      },
      "source": [
        "## Connecting to cloud hardware"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHyTDoHT9zHG",
        "outputId": "17068d52-8593-42cc-c9a0-53228fc6822c"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "  raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYeVLXrg91A-",
        "outputId": "a2bc6756-ca56-4f78-dc64-315af387c6a2"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print('There are %d GPU(s) available' % torch.cuda.device_count())\n",
        "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print('No GPU available, using CPU')\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOs8pOTD-FPw"
      },
      "source": [
        "## Importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh3Euzfa-A2k",
        "outputId": "6bb47169-1283-4b9b-ed5f-faff8dad97a8"
      },
      "source": [
        "df = pd.read_csv('/content/final_consolidated_data')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>CIK Code</th>\n",
              "      <th>Filing</th>\n",
              "      <th>Date Filed</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>CompanyName</th>\n",
              "      <th>PrevAvgPriceChange</th>\n",
              "      <th>PostAvgPriceChange</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1680378</td>\n",
              "      <td>Investing in ourshares of common stock involve...</td>\n",
              "      <td>2021-03-18</td>\n",
              "      <td>SNES</td>\n",
              "      <td>SenesTech, Inc.</td>\n",
              "      <td>0.001328</td>\n",
              "      <td>-0.003177</td>\n",
              "      <td>decrease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1222719</td>\n",
              "      <td>Investing in any of our securities involves ri...</td>\n",
              "      <td>2021-01-31</td>\n",
              "      <td>CHY</td>\n",
              "      <td>CALAMOS CONVERTIBLE &amp; HIGH INCOME FUND</td>\n",
              "      <td>0.004126</td>\n",
              "      <td>0.006552</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1364954</td>\n",
              "      <td>An investment in our securities involves a hig...</td>\n",
              "      <td>2021-04-03</td>\n",
              "      <td>CHGG</td>\n",
              "      <td>CHEGG, INC</td>\n",
              "      <td>0.065078</td>\n",
              "      <td>0.011987</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1674930</td>\n",
              "      <td>Investing in our common stock involves risk. B...</td>\n",
              "      <td>2020-08-12</td>\n",
              "      <td>FLGT</td>\n",
              "      <td>Fulgent Genetics, Inc.</td>\n",
              "      <td>0.412805</td>\n",
              "      <td>0.058477</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1409375</td>\n",
              "      <td>Investing in our common stock involves a high ...</td>\n",
              "      <td>2021-03-10</td>\n",
              "      <td>OESX</td>\n",
              "      <td>ORION ENERGY SYSTEMS, INC.</td>\n",
              "      <td>-0.046603</td>\n",
              "      <td>-0.002521</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  CIK Code  ... PostAvgPriceChange     Label\n",
              "0           0   1680378  ...          -0.003177  decrease\n",
              "1           1   1222719  ...           0.006552   neutral\n",
              "2           2   1364954  ...           0.011987   neutral\n",
              "3           3   1674930  ...           0.058477   neutral\n",
              "4           4   1409375  ...          -0.002521   neutral\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flnfY8FH-I6p",
        "outputId": "874f9064-8785-49fd-8373-9877cebae12f"
      },
      "source": [
        "df.drop(columns = 'Unnamed: 0', inplace = True)\n",
        "df.dropna(axis = 0, how = 'any', inplace = True)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1350 entries, 0 to 1349\n",
            "Data columns (total 8 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   CIK Code            1350 non-null   int64  \n",
            " 1   Filing              1350 non-null   object \n",
            " 2   Date Filed          1350 non-null   object \n",
            " 3   Ticker              1350 non-null   object \n",
            " 4   CompanyName         1350 non-null   object \n",
            " 5   PrevAvgPriceChange  1350 non-null   float64\n",
            " 6   PostAvgPriceChange  1350 non-null   float64\n",
            " 7   Label               1350 non-null   object \n",
            "dtypes: float64(2), int64(1), object(5)\n",
            "memory usage: 94.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-HQxfhuJpld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf2612e-e123-44ff-a7b5-11e9889a11e4"
      },
      "source": [
        "incr_counts = 0\n",
        "decr_counts = 0\n",
        "neutral_counts = 0\n",
        "\n",
        "for i in df.Label:\n",
        "  if i == 'increase':\n",
        "    incr_counts += 1\n",
        "  elif i == 'decrease':\n",
        "    decr_counts += 1\n",
        "\n",
        "neutral_counts = len(df) - (incr_counts + decr_counts)\n",
        "\n",
        "counts = [incr_counts, decr_counts, neutral_counts]\n",
        "labs = ['increase', 'decrease', 'neutral']\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "color = 'lightsteelblue'\n",
        "\n",
        "plt.bar(labs, counts, color = color)\n",
        "plt.ylim([100, 900])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-rw1cTL-SFP"
      },
      "source": [
        "## Model import and configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYJVsWRf-Ub3",
        "outputId": "30d89502-1bca-4556-f6d6-44a1b574a02c"
      },
      "source": [
        "# importing model\n",
        "bert = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased',\n",
        "                                                          num_labels = 3)\n",
        "config = bert.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXRIQ_jD_oi-",
        "outputId": "fe29154c-8508-4450-82e6-5859bf1bf5e7"
      },
      "source": [
        "#changing labels\n",
        "config.max_position_embeddings = 300\n",
        "config.id2label[0] = 'decrease'\n",
        "config.id2label[1] = 'neutral'\n",
        "config.id2label[2] = 'increase'\n",
        "config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"bert-base-uncased\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"decrease\",\n",
              "    \"1\": \"neutral\",\n",
              "    \"2\": \"increase\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"label2id\": {\n",
              "    \"LABEL_0\": 0,\n",
              "    \"LABEL_1\": 1,\n",
              "    \"LABEL_2\": 2\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 300,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.6.0.dev0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReH4TpZJEO2F",
        "outputId": "ce540c25-5a60-46d3-ba7a-ab67d8cf7074"
      },
      "source": [
        "config.label2id['decrease'] = config.label2id['LABEL_0']\n",
        "config.label2id['neutral'] = config.label2id['LABEL_1']\n",
        "config.label2id['increase'] = config.label2id['LABEL_2']\n",
        "del config.label2id['LABEL_0']\n",
        "del config.label2id['LABEL_1']\n",
        "del config.label2id['LABEL_2']\n",
        "config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"bert-base-uncased\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"decrease\",\n",
              "    \"1\": \"neutral\",\n",
              "    \"2\": \"increase\"\n",
              "  },\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"label2id\": {\n",
              "    \"decrease\": 0,\n",
              "    \"increase\": 2,\n",
              "    \"neutral\": 1\n",
              "  },\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 300,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.6.0.dev0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKBk_cL714Dx"
      },
      "source": [
        "config.hidden_dropout_prob = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6CfUzZg_qji"
      },
      "source": [
        "# importing tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', use_fast = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpIIPPPIAiIC",
        "outputId": "a197f635-f358-4533-d5cb-b167d08e68b5"
      },
      "source": [
        "tokenizer.model_max_length = 300\n",
        "tokenizer.model_max_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlYSy4cHnS3W"
      },
      "source": [
        "TUNE PARAMETERS HERE !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLk7ty1cBDAx"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "lr = 1e-5\n",
        "early_stopping = early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = 'val_loss',\n",
        "    verbose = 1,\n",
        "    patience = 10,\n",
        "    mode = 'max',\n",
        "    restore_best_weights = True\n",
        ")\n",
        "auto = tf.data.experimental.AUTOTUNE\n",
        "max_seq_length = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOk49lL9Bc8R"
      },
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1cLvhoPULLg"
      },
      "source": [
        "BERT's word embeddings are really good, and they do really well processing completely unstructured and unprocessed data. But in order to minimize the amount of data to be used (we have to spare our GPU memory) we are going to remove stop words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQFpzulomajq"
      },
      "source": [
        "# Stop word removal\n",
        "def remove_stopwords(text):\n",
        "  filtered = []\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  word_tokens = word_tokenize(text)\n",
        "  for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "      filtered.append(w)\n",
        "  filtered_doc = ' '.join(str(i) for i in filtered)\n",
        "  return filtered_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_X0thZGmhFm"
      },
      "source": [
        "df['Filing'] = df['Filing'].apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRRhGQNtBe5B"
      },
      "source": [
        "#train/test splitting\n",
        "x = df.Filing.values\n",
        "y = df.Label.values\n",
        "labs = []\n",
        "\n",
        "for i in y:\n",
        "  if i == 'decrease':\n",
        "    labs.append(0)\n",
        "  elif i == 'neutral':\n",
        "    labs.append(1)\n",
        "  else:\n",
        "    labs.append(2)\n",
        "labs = np.array(labs)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, labs, test_size = 0.3, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArOpCzvLB4p3"
      },
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(x_train, y_train, test_size =0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw75kVL3B8F0"
      },
      "source": [
        "train_encodings = tokenizer(list(train_texts),\n",
        "                            truncation = True,\n",
        "                            padding = True,\n",
        "                            return_overflowing_tokens = True,\n",
        "                            return_offsets_mapping = True,\n",
        "                            stride = 100,\n",
        "                            max_length = max_seq_length,\n",
        "                            return_tensors = 'pt')\n",
        "\n",
        "val_encodings = tokenizer(list(val_texts),\n",
        "                          truncation = True,\n",
        "                          padding = True,\n",
        "                          return_overflowing_tokens = True,\n",
        "                          return_offsets_mapping = True,\n",
        "                          stride = 100,\n",
        "                          max_length = max_seq_length,\n",
        "                          return_tensors = 'pt')\n",
        "\n",
        "test_encodings = tokenizer(list(x_test),\n",
        "                           truncation = True,\n",
        "                           padding = True,\n",
        "                           return_overflowing_tokens = True, \n",
        "                           return_offsets_mapping = True,\n",
        "                           stride = 100, \n",
        "                           max_length = max_seq_length,\n",
        "                           return_tensors = 'pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC_XIvFbnr1G"
      },
      "source": [
        "The cell above tokenizes and splits the filings into the sub-filings of length 300, with a 100 token overlap with its neighboring sub-filings. Now we have to map each window to its respective label. For this we use the offsets mapping that was returned. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAc3b9OtnqJV"
      },
      "source": [
        "train_sub_labs = []\n",
        "val_sub_labs = []\n",
        "test_sub_labs = []\n",
        "\n",
        "for idx, lab in enumerate(train_labels):\n",
        "  for i in train_encodings['overflow_to_sample_mapping']:\n",
        "    if i == idx:\n",
        "      train_sub_labs.append(lab)\n",
        "\n",
        "for idx, lab in enumerate(val_labels):\n",
        "  for i in val_encodings['overflow_to_sample_mapping']:\n",
        "    if i == idx:\n",
        "      val_sub_labs.append(lab)\n",
        "\n",
        "for idx, lab in enumerate(y_test):\n",
        "  for i in test_encodings['overflow_to_sample_mapping']:\n",
        "    if i == idx:\n",
        "      test_sub_labs.append(lab)\n",
        "\n",
        "train_sub_labs = np.array(train_sub_labs)\n",
        "val_sub_labs = np.array(val_sub_labs)\n",
        "test_sub_labs = np.array(test_sub_labs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiQPf-ZWotvw"
      },
      "source": [
        "Now that we have each window mapped with their label, we have to make sure that our inputs are correct. We actually used the overflowing tokens and offsets mapping for the steps above, but BERT does not recognize them as input, so we need to take them out. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6qFZrMvo8Jh",
        "outputId": "fd12a975-a2c7-4840-e5dd-e336cd1082c5"
      },
      "source": [
        "tokenizer.model_input_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['input_ids', 'token_type_ids', 'attention_mask']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkLlw3aAo_CL",
        "outputId": "8312146a-850b-4354-a57e-b8d65f122b64"
      },
      "source": [
        "train_encodings.keys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BatchEncoding.keys of {'input_ids': tensor([[  101,  8875, 20720,  ...,  6855,  3176,   102],\n",
              "        [  101,  4598,  7790,  ...,  3325,  4022,   102],\n",
              "        [  101,  2256,  4945,  ...,  1012,  2256,   102],\n",
              "        ...,\n",
              "        [  101,  6226,  1012,  ...,  7080,  4295,   102],\n",
              "        [  101,  1011,  1057,  ...,  8875, 20720,   102],\n",
              "        [  101,  3795,  4425,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]]), 'offset_mapping': tensor([[[     0,      0],\n",
              "         [     0,      4],\n",
              "         [     5,      7],\n",
              "         ...,\n",
              "         [  1957,   1963],\n",
              "         [  1964,   1974],\n",
              "         [     0,      0]],\n",
              "\n",
              "        [[     0,      0],\n",
              "         [  1314,   1323],\n",
              "         [  1324,   1333],\n",
              "         ...,\n",
              "         [  3356,   3366],\n",
              "         [  3367,   3376],\n",
              "         [     0,      0]],\n",
              "\n",
              "        [[     0,      0],\n",
              "         [  2698,   2701],\n",
              "         [  2702,   2709],\n",
              "         ...,\n",
              "         [  4643,   4644],\n",
              "         [  4645,   4648],\n",
              "         [     0,      0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[     0,      0],\n",
              "         [104173, 104181],\n",
              "         [104182, 104183],\n",
              "         ...,\n",
              "         [105865, 105876],\n",
              "         [105877, 105884],\n",
              "         [     0,      0]],\n",
              "\n",
              "        [[     0,      0],\n",
              "         [105259, 105260],\n",
              "         [105260, 105261],\n",
              "         ...,\n",
              "         [107222, 107226],\n",
              "         [107227, 107229],\n",
              "         [     0,      0]],\n",
              "\n",
              "        [[     0,      0],\n",
              "         [106595, 106601],\n",
              "         [106602, 106608],\n",
              "         ...,\n",
              "         [     0,      0],\n",
              "         [     0,      0],\n",
              "         [     0,      0]]]), 'overflow_to_sample_mapping': tensor([  0,   0,   0,  ..., 755, 755, 755])}>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N52JO15BpKgi",
        "outputId": "b1f3cc7c-3654-4bfa-91c8-3c5e762ca358"
      },
      "source": [
        "train_encodings.pop('overflow_to_sample_mapping')\n",
        "train_encodings.pop('offset_mapping')\n",
        "test_encodings.pop('overflow_to_sample_mapping')\n",
        "test_encodings.pop('offset_mapping')\n",
        "val_encodings.pop('overflow_to_sample_mapping')\n",
        "val_encodings.pop('offset_mapping')\n",
        "train_encodings.keys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BatchEncoding.keys of {'input_ids': tensor([[  101,  8875, 20720,  ...,  6855,  3176,   102],\n",
              "        [  101,  4598,  7790,  ...,  3325,  4022,   102],\n",
              "        [  101,  2256,  4945,  ...,  1012,  2256,   102],\n",
              "        ...,\n",
              "        [  101,  6226,  1012,  ...,  7080,  4295,   102],\n",
              "        [  101,  1011,  1057,  ...,  8875, 20720,   102],\n",
              "        [  101,  3795,  4425,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])}>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etFnYjgjpSmQ"
      },
      "source": [
        "Now that inputs are ready, we can create the PyTorch datasets with the encodings and the labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROGi0M_0B_u4"
      },
      "source": [
        "class SEC_Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "    self.encodings = encodings\n",
        "    self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    item['labels'] = torch.tensor(self.labels[idx])\n",
        "    return item\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "train_dataset = SEC_Dataset(train_encodings, train_sub_labs)\n",
        "val_dataset = SEC_Dataset(val_encodings, val_sub_labs)\n",
        "test_dataset = SEC_Dataset(test_encodings, test_sub_labs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaBLlkxWCKiR"
      },
      "source": [
        "## Performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-mnWTOhCL1M"
      },
      "source": [
        "# custom metrics\n",
        "def compute_metrics(eval_pred):\n",
        "  labels = eval_pred.label_ids\n",
        "  preds = eval_pred.predictions.argmax(-1)\n",
        "  lab_names = [0,1,2]\n",
        "  \n",
        "  precision, recall, f1, support = precision_recall_fscore_support(labels, preds, average ='weighted')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  print(precision_recall_fscore_support(labels, preds, average = None, labels = lab_names))\n",
        "\n",
        "  dic = {\n",
        "      'Accuracy': acc,\n",
        "      'F1': f1,\n",
        "      'Precision': precision,\n",
        "      'Recall': recall,\n",
        "      'Support': support\n",
        "  }\n",
        "  return dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM0wlobJCP2P"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWDMV8MCoCXu"
      },
      "source": [
        "# overriding trainer class to log metrics during training --> evaluate overfitting\n",
        "class MyTrainer(Trainer):\n",
        "  def __init__(self, model,\n",
        "        args = None,\n",
        "        data_collator = None,\n",
        "        train_dataset = None,\n",
        "        eval_dataset = None,\n",
        "        tokenizer = None,\n",
        "        model_init = None,\n",
        "        compute_metrics = None,\n",
        "        callbacks = None,\n",
        "        optimizers = (None,None)\n",
        "    ):\n",
        "\n",
        "    super().__init__(model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init,\n",
        "                  compute_metrics, callbacks, optimizers) \n",
        "    \n",
        "  def evaluate(\n",
        "        self,\n",
        "        train_dataset = None,\n",
        "        eval_dataset: Optional[Dataset] = None,\n",
        "        ignore_keys: Optional[List[str]] = None,\n",
        "        metric_key_prefix: str = \"eval\",\n",
        "    ) -> Dict[str, float]:\n",
        "        \n",
        "        # memory metrics - must set up as early as possible\n",
        "        self._memory_tracker.start()\n",
        "\n",
        "        if eval_dataset is not None and not isinstance(eval_dataset, collections.abc.Sized):\n",
        "            raise ValueError(\"eval_dataset must implement __len__\")\n",
        "\n",
        "        train_dataloader = self.get_train_dataloader()\n",
        "        eval_dataloader = self.get_eval_dataloader(eval_dataset)\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_output = self.prediction_loop(\n",
        "            train_dataloader,\n",
        "            description = 'Training',\n",
        "            prediction_loss_only = True if self.compute_metrics is None else None,\n",
        "            ignore_keys = ignore_keys,\n",
        "            metric_key_prefix = 'train',\n",
        "            )\n",
        "\n",
        "\n",
        "        eval_output = self.prediction_loop(\n",
        "            eval_dataloader,\n",
        "            description=\"Evaluation\",\n",
        "            # No point gathering the predictions if there are no metrics, otherwise we defer to\n",
        "            # self.args.prediction_loss_only\n",
        "            prediction_loss_only=True if self.compute_metrics is None else None,\n",
        "            ignore_keys=ignore_keys,\n",
        "            metric_key_prefix=metric_key_prefix,\n",
        "        )\n",
        "        train_n_samples = len(self.train_dataset)\n",
        "        train_output.metrics.update(speed_metrics('train', start_time, train_n_samples))\n",
        "        self.log(train_output.metrics)\n",
        "\n",
        "        eval_n_samples = len(eval_dataset if eval_dataset is not None else self.eval_dataset)\n",
        "        eval_output.metrics.update(speed_metrics(metric_key_prefix, start_time, eval_n_samples))\n",
        "        self.log(eval_output.metrics)\n",
        "\n",
        "        if self.args.tpu_metrics_debug or self.args.debug:\n",
        "            # tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\n",
        "            xm.master_print(met.metrics_report())\n",
        "        \n",
        "        train_output.metrics['eval_loss'] = 'No log'\n",
        "        self.control = self.callback_handler.on_evaluate(self.args, self.state, self.control, eval_output.metrics)\n",
        "        self.control = self.callback_handler.on_evaluate(self.args, self.state, self.control, train_output.metrics)\n",
        "\n",
        "        self._memory_tracker.stop_and_update_metrics(train_output.metrics)\n",
        "        self._memory_tracker.stop_and_update_metrics(eval_output.metrics)\n",
        "\n",
        "        dic = {\n",
        "        'Training metrics': train_output.metrics,\n",
        "        'Validation metrics': eval_output.metrics\n",
        "        }\n",
        "\n",
        "        return dic\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVGuMJDN2RNb"
      },
      "source": [
        "<b>NOTE</b> below two rows per epoch are reported since it prints one row for the evaluation, and one row for training. That's why there is no log in the second row for validation loss, and why the training loss is the same for the two rows. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SvsG51khCQ4p",
        "outputId": "6dc08f42-73c1-431e-ade0-59b2dd7bc859"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = 'BERT',\n",
        "    num_train_epochs = epochs,\n",
        "    do_train = True,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    logging_strategy = 'epoch',\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    warmup_steps = 250,\n",
        "    weight_decay = 0.2,\n",
        "    gradient_accumulation_steps = 3,\n",
        "    learning_rate = 1e-5,\n",
        "    fp16 = True \n",
        ")\n",
        "\n",
        "trainer = MyTrainer(\n",
        "    model = bert,\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = val_dataset,\n",
        "    compute_metrics = compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 2:58:19, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.043200</td>\n",
              "      <td>1.065484</td>\n",
              "      <td>0.459409</td>\n",
              "      <td>0.441004</td>\n",
              "      <td>0.452141</td>\n",
              "      <td>0.459409</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.043200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.556718</td>\n",
              "      <td>0.548049</td>\n",
              "      <td>0.566872</td>\n",
              "      <td>0.556718</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.846400</td>\n",
              "      <td>1.075785</td>\n",
              "      <td>0.505265</td>\n",
              "      <td>0.484164</td>\n",
              "      <td>0.509036</td>\n",
              "      <td>0.505265</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.846400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.710893</td>\n",
              "      <td>0.703463</td>\n",
              "      <td>0.726439</td>\n",
              "      <td>0.710893</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.651200</td>\n",
              "      <td>0.996068</td>\n",
              "      <td>0.570652</td>\n",
              "      <td>0.563971</td>\n",
              "      <td>0.566603</td>\n",
              "      <td>0.570652</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.651200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.805249</td>\n",
              "      <td>0.804922</td>\n",
              "      <td>0.808433</td>\n",
              "      <td>0.805249</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.529800</td>\n",
              "      <td>0.988709</td>\n",
              "      <td>0.592221</td>\n",
              "      <td>0.590958</td>\n",
              "      <td>0.594767</td>\n",
              "      <td>0.592221</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.529800</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.839143</td>\n",
              "      <td>0.839659</td>\n",
              "      <td>0.846169</td>\n",
              "      <td>0.839143</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.450200</td>\n",
              "      <td>1.038999</td>\n",
              "      <td>0.605639</td>\n",
              "      <td>0.600970</td>\n",
              "      <td>0.602100</td>\n",
              "      <td>0.605639</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.450200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.878794</td>\n",
              "      <td>0.878524</td>\n",
              "      <td>0.878640</td>\n",
              "      <td>0.878794</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.385100</td>\n",
              "      <td>1.099005</td>\n",
              "      <td>0.609885</td>\n",
              "      <td>0.604747</td>\n",
              "      <td>0.611171</td>\n",
              "      <td>0.609885</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.385100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.891675</td>\n",
              "      <td>0.891328</td>\n",
              "      <td>0.891856</td>\n",
              "      <td>0.891675</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.345500</td>\n",
              "      <td>1.124913</td>\n",
              "      <td>0.618546</td>\n",
              "      <td>0.613753</td>\n",
              "      <td>0.615800</td>\n",
              "      <td>0.618546</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.345500</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.904114</td>\n",
              "      <td>0.904049</td>\n",
              "      <td>0.904024</td>\n",
              "      <td>0.904114</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.312800</td>\n",
              "      <td>1.133430</td>\n",
              "      <td>0.620075</td>\n",
              "      <td>0.618157</td>\n",
              "      <td>0.617330</td>\n",
              "      <td>0.620075</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.312800</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.906650</td>\n",
              "      <td>0.906775</td>\n",
              "      <td>0.907042</td>\n",
              "      <td>0.906650</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.293300</td>\n",
              "      <td>1.169703</td>\n",
              "      <td>0.624830</td>\n",
              "      <td>0.619775</td>\n",
              "      <td>0.621025</td>\n",
              "      <td>0.624830</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.293300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.912286</td>\n",
              "      <td>0.912244</td>\n",
              "      <td>0.912407</td>\n",
              "      <td>0.912286</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.276100</td>\n",
              "      <td>1.192482</td>\n",
              "      <td>0.626019</td>\n",
              "      <td>0.620563</td>\n",
              "      <td>0.622834</td>\n",
              "      <td>0.626019</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.276100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.915385</td>\n",
              "      <td>0.915269</td>\n",
              "      <td>0.915355</td>\n",
              "      <td>0.915385</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py:368: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.51365751, 0.59484385, 0.59856115]), array([0.68687097, 0.57936103, 0.33537569]), array([0.58776853, 0.58700036, 0.4298853 ]), array([8843, 9797, 6202]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"train/train_Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"eval/Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.50368236, 0.40789474, 0.41374474]), array([0.59969501, 0.49821429, 0.18611987]), array([0.54751131, 0.44855305, 0.256745  ]), array([2623, 1680, 1585]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py:368: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.68699229, 0.69335517, 0.83494593]), array([0.75551284, 0.82116975, 0.4730732 ]), array([0.71962516, 0.75186916, 0.60395224]), array([8843, 9797, 6202]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"train/train_Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"eval/Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.55397924, 0.44739057, 0.5       ]), array([0.61036981, 0.6327381 , 0.19621451]), array([0.580809  , 0.52416174, 0.28183054]), array([2623, 1680, 1585]))\n",
            "(array([0.75837031, 0.84047469, 0.82920059]), array([0.85039014, 0.81688272, 0.72250887]), array([0.80174849, 0.82851079, 0.7721868 ]), array([8843, 9797, 6202]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"train/train_Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"eval/Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.59337748, 0.55426582, 0.53537118]), array([0.68318719, 0.56845238, 0.38675079]), array([0.63512316, 0.56126947, 0.44908425]), array([2623, 1680, 1585]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py:368: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.82535631, 0.91612213, 0.76534245]), array([0.87753025, 0.78707768, 0.86665592]), array([0.85064401, 0.84671132, 0.81285444]), array([8843, 9797, 6202]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"train/train_Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"eval/Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.61990325, 0.64956012, 0.49509202]), array([0.68394968, 0.52738095, 0.50914826]), array([0.65035345, 0.58212878, 0.50202177]), array([2623, 1680, 1585]))\n",
            "(array([0.87702703, 0.88487921, 0.8710825 ]), array([0.8806966 , 0.90854343, 0.82908739]), array([0.87885798, 0.8965552 , 0.84956629]), array([8843, 9797, 6202]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"train/train_Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"eval/Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.63866145, 0.58833063, 0.55618893]), array([0.68394968, 0.64821429, 0.43091483]), array([0.66053019, 0.61682243, 0.48560256]), array([2623, 1680, 1585]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py:368: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.9002983 , 0.88458175, 0.89130807]), array([0.88736854, 0.92936613, 0.83827797]), array([0.89378666, 0.90642111, 0.86398006]), array([8843, 9797, 6202]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"train/train_Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"eval/Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.65354623, 0.5622276 , 0.59292035]), array([0.67098742, 0.69107143, 0.42271293]), array([0.66215199, 0.6200267 , 0.49355433]), array([2623, 1680, 1585]))\n",
            "(array([0.90387213, 0.91446834, 0.88774172]), array([0.90806287, 0.9199755 , 0.87342793]), array([0.90596266, 0.91721366, 0.88052666]), array([8843, 9797, 6202]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"train/train_Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"eval/Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.64807624, 0.59675676, 0.58257261]), array([0.69996188, 0.65714286, 0.44290221]), array([0.67302053, 0.62549575, 0.50322581]), array([2623, 1680, 1585]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py:368: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.91300387, 0.92500259, 0.8701705 ]), array([0.90670587, 0.91272839, 0.89696872]), array([0.90984397, 0.9188245 , 0.88336642]), array([8843, 9797, 6202]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"train/train_Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"eval/Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.65398551, 0.62868949, 0.5446304 ]), array([0.68814335, 0.63392857, 0.49274448]), array([0.67062976, 0.63129816, 0.51738986]), array([2623, 1680, 1585]))\n",
            "(array([0.90212251, 0.9282099 , 0.90210943]), array([0.92762637, 0.91721956, 0.88261851]), array([0.9146967 , 0.922682  , 0.89225754]), array([8843, 9797, 6202]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"train/train_Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"eval/Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.64414875, 0.62514484, 0.57839155]), array([0.7197865 , 0.6422619 , 0.44921136]), array([0.67987036, 0.63358779, 0.50568182]), array([2623, 1680, 1585]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py:368: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.91067053, 0.92190187, 0.91169092]), array([0.92457311, 0.93018271, 0.87891003]), array([0.91756916, 0.92602378, 0.89500041]), array([8843, 9797, 6202]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"train/train_Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"None\" of type <class 'NoneType'> for key \"eval/Support\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.65117892, 0.60967565, 0.58987342]), array([0.71597408, 0.66011905, 0.44100946]), array([0.68204104, 0.6338954 , 0.50469314]), array([2623, 1680, 1585]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2590, training_loss=0.5133533669254494, metrics={'train_runtime': 10702.8138, 'train_samples_per_second': 0.242, 'total_flos': 1698368086882800.0, 'epoch': 10.0, 'init_mem_cpu_alloc_delta': 61440, 'init_mem_gpu_alloc_delta': 439355904, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': -1972228096, 'train_mem_gpu_alloc_delta': 1341046784, 'train_mem_cpu_peaked_delta': 1972477952, 'train_mem_gpu_peaked_delta': 9656779776})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQbikfhd2yw5",
        "outputId": "98f95176-4c1a-4848-f286-76fca44d8c2f"
      },
      "source": [
        "trainer.state.log_history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'epoch': 1.0,\n",
              "  'learning_rate': 9.961538461538463e-06,\n",
              "  'loss': 1.0432,\n",
              "  'step': 259},\n",
              " {'epoch': 1.0,\n",
              "  'step': 259,\n",
              "  'train_Accuracy': 0.5567184606714435,\n",
              "  'train_F1': 0.5480487990543723,\n",
              "  'train_Precision': 0.5668720215576611,\n",
              "  'train_Recall': 0.5567184606714435,\n",
              "  'train_Support': None,\n",
              "  'train_loss': 0.9318682551383972,\n",
              "  'train_runtime': 299.4548,\n",
              "  'train_samples_per_second': 82.957},\n",
              " {'epoch': 1.0,\n",
              "  'eval_Accuracy': 0.4594089673913043,\n",
              "  'eval_F1': 0.44100409678688807,\n",
              "  'eval_Precision': 0.4521412013052532,\n",
              "  'eval_Recall': 0.4594089673913043,\n",
              "  'eval_Support': None,\n",
              "  'eval_loss': 1.0654839277267456,\n",
              "  'eval_runtime': 299.4627,\n",
              "  'eval_samples_per_second': 19.662,\n",
              "  'step': 259},\n",
              " {'epoch': 2.0,\n",
              "  'learning_rate': 8.854700854700855e-06,\n",
              "  'loss': 0.8464,\n",
              "  'step': 518},\n",
              " {'epoch': 2.0,\n",
              "  'step': 518,\n",
              "  'train_Accuracy': 0.710892842766283,\n",
              "  'train_F1': 0.7034626547316261,\n",
              "  'train_Precision': 0.7264394184135554,\n",
              "  'train_Recall': 0.710892842766283,\n",
              "  'train_Support': None,\n",
              "  'train_loss': 0.6862392425537109,\n",
              "  'train_runtime': 299.4021,\n",
              "  'train_samples_per_second': 82.972},\n",
              " {'epoch': 2.0,\n",
              "  'eval_Accuracy': 0.505264945652174,\n",
              "  'eval_F1': 0.4841635732862862,\n",
              "  'eval_Precision': 0.5090359553105905,\n",
              "  'eval_Recall': 0.505264945652174,\n",
              "  'eval_Support': None,\n",
              "  'eval_loss': 1.0757845640182495,\n",
              "  'eval_runtime': 299.4047,\n",
              "  'eval_samples_per_second': 19.666,\n",
              "  'step': 518},\n",
              " {'epoch': 3.0,\n",
              "  'learning_rate': 7.74786324786325e-06,\n",
              "  'loss': 0.6512,\n",
              "  'step': 777},\n",
              " {'epoch': 3.0,\n",
              "  'step': 777,\n",
              "  'train_Accuracy': 0.8052491747846389,\n",
              "  'train_F1': 0.804922498191688,\n",
              "  'train_Precision': 0.8084333495313517,\n",
              "  'train_Recall': 0.8052491747846389,\n",
              "  'train_Support': None,\n",
              "  'train_loss': 0.49035441875457764,\n",
              "  'train_runtime': 299.3414,\n",
              "  'train_samples_per_second': 82.989},\n",
              " {'epoch': 3.0,\n",
              "  'eval_Accuracy': 0.5706521739130435,\n",
              "  'eval_F1': 0.5639706680856659,\n",
              "  'eval_Precision': 0.5666030957517492,\n",
              "  'eval_Recall': 0.5706521739130435,\n",
              "  'eval_Support': None,\n",
              "  'eval_loss': 0.9960682988166809,\n",
              "  'eval_runtime': 299.3454,\n",
              "  'eval_samples_per_second': 19.67,\n",
              "  'step': 777},\n",
              " {'epoch': 4.0,\n",
              "  'learning_rate': 6.641025641025641e-06,\n",
              "  'loss': 0.5298,\n",
              "  'step': 1036},\n",
              " {'epoch': 4.0,\n",
              "  'step': 1036,\n",
              "  'train_Accuracy': 0.839143386200789,\n",
              "  'train_F1': 0.8396586048430579,\n",
              "  'train_Precision': 0.8461689163728828,\n",
              "  'train_Recall': 0.839143386200789,\n",
              "  'train_Support': None,\n",
              "  'train_loss': 0.40827545523643494,\n",
              "  'train_runtime': 299.4085,\n",
              "  'train_samples_per_second': 82.97},\n",
              " {'epoch': 4.0,\n",
              "  'eval_Accuracy': 0.5922214673913043,\n",
              "  'eval_F1': 0.5909575346712397,\n",
              "  'eval_Precision': 0.5947669965570966,\n",
              "  'eval_Recall': 0.5922214673913043,\n",
              "  'eval_Support': None,\n",
              "  'eval_loss': 0.9887093305587769,\n",
              "  'eval_runtime': 299.4153,\n",
              "  'eval_samples_per_second': 19.665,\n",
              "  'step': 1036},\n",
              " {'epoch': 5.0,\n",
              "  'learning_rate': 5.538461538461539e-06,\n",
              "  'loss': 0.4502,\n",
              "  'step': 1295},\n",
              " {'epoch': 5.0,\n",
              "  'step': 1295,\n",
              "  'train_Accuracy': 0.8787939779405844,\n",
              "  'train_F1': 0.8785243763616815,\n",
              "  'train_Precision': 0.8786396149228539,\n",
              "  'train_Recall': 0.8787939779405844,\n",
              "  'train_Support': None,\n",
              "  'train_loss': 0.31938764452934265,\n",
              "  'train_runtime': 299.4188,\n",
              "  'train_samples_per_second': 82.967},\n",
              " {'epoch': 5.0,\n",
              "  'eval_Accuracy': 0.6056385869565217,\n",
              "  'eval_F1': 0.600970181949078,\n",
              "  'eval_Precision': 0.6020998436363224,\n",
              "  'eval_Recall': 0.6056385869565217,\n",
              "  'eval_Support': None,\n",
              "  'eval_loss': 1.038999319076538,\n",
              "  'eval_runtime': 299.4217,\n",
              "  'eval_samples_per_second': 19.665,\n",
              "  'step': 1295},\n",
              " {'epoch': 6.0,\n",
              "  'learning_rate': 4.431623931623932e-06,\n",
              "  'loss': 0.3851,\n",
              "  'step': 1554},\n",
              " {'epoch': 6.0,\n",
              "  'step': 1554,\n",
              "  'train_Accuracy': 0.8916753884550358,\n",
              "  'train_F1': 0.8913278858275677,\n",
              "  'train_Precision': 0.8918556482431134,\n",
              "  'train_Recall': 0.8916753884550358,\n",
              "  'train_Support': None,\n",
              "  'train_loss': 0.2733137607574463,\n",
              "  'train_runtime': 299.3727,\n",
              "  'train_samples_per_second': 82.98},\n",
              " {'epoch': 6.0,\n",
              "  'eval_Accuracy': 0.6098845108695652,\n",
              "  'eval_F1': 0.6047474778532942,\n",
              "  'eval_Precision': 0.6111706687797998,\n",
              "  'eval_Recall': 0.6098845108695652,\n",
              "  'eval_Support': None,\n",
              "  'eval_loss': 1.0990045070648193,\n",
              "  'eval_runtime': 299.3785,\n",
              "  'eval_samples_per_second': 19.667,\n",
              "  'step': 1554},\n",
              " {'epoch': 7.0,\n",
              "  'learning_rate': 3.324786324786325e-06,\n",
              "  'loss': 0.3455,\n",
              "  'step': 1813},\n",
              " {'epoch': 7.0,\n",
              "  'step': 1813,\n",
              "  'train_Accuracy': 0.9041140004830529,\n",
              "  'train_F1': 0.9040494443110567,\n",
              "  'train_Precision': 0.9040239023742359,\n",
              "  'train_Recall': 0.9041140004830529,\n",
              "  'train_Support': None,\n",
              "  'train_loss': 0.2405710518360138,\n",
              "  'train_runtime': 299.3606,\n",
              "  'train_samples_per_second': 82.984},\n",
              " {'epoch': 7.0,\n",
              "  'eval_Accuracy': 0.618546195652174,\n",
              "  'eval_F1': 0.6137531604942915,\n",
              "  'eval_Precision': 0.6158004302678161,\n",
              "  'eval_Recall': 0.618546195652174,\n",
              "  'eval_Support': None,\n",
              "  'eval_loss': 1.1249126195907593,\n",
              "  'eval_runtime': 299.369,\n",
              "  'eval_samples_per_second': 19.668,\n",
              "  'step': 1813},\n",
              " {'epoch': 8.0,\n",
              "  'learning_rate': 2.217948717948718e-06,\n",
              "  'loss': 0.3128,\n",
              "  'step': 2072},\n",
              " {'epoch': 8.0,\n",
              "  'step': 2072,\n",
              "  'train_Accuracy': 0.9066500281780855,\n",
              "  'train_F1': 0.9067753136121026,\n",
              "  'train_Precision': 0.9070421466489968,\n",
              "  'train_Recall': 0.9066500281780855,\n",
              "  'train_Support': None,\n",
              "  'train_loss': 0.2274634838104248,\n",
              "  'train_runtime': 299.3559,\n",
              "  'train_samples_per_second': 82.985},\n",
              " {'epoch': 8.0,\n",
              "  'eval_Accuracy': 0.6200747282608695,\n",
              "  'eval_F1': 0.6181565402556458,\n",
              "  'eval_Precision': 0.6173304218221133,\n",
              "  'eval_Recall': 0.6200747282608695,\n",
              "  'eval_Support': None,\n",
              "  'eval_loss': 1.1334296464920044,\n",
              "  'eval_runtime': 299.3584,\n",
              "  'eval_samples_per_second': 19.669,\n",
              "  'step': 2072},\n",
              " {'epoch': 9.0,\n",
              "  'learning_rate': 1.111111111111111e-06,\n",
              "  'loss': 0.2933,\n",
              "  'step': 2331},\n",
              " {'epoch': 9.0,\n",
              "  'step': 2331,\n",
              "  'train_Accuracy': 0.9122856452781579,\n",
              "  'train_F1': 0.9122437695710365,\n",
              "  'train_Precision': 0.9124073900287146,\n",
              "  'train_Recall': 0.9122856452781579,\n",
              "  'train_Support': None,\n",
              "  'train_loss': 0.21320722997188568,\n",
              "  'train_runtime': 299.4033,\n",
              "  'train_samples_per_second': 82.972},\n",
              " {'epoch': 9.0,\n",
              "  'eval_Accuracy': 0.6248301630434783,\n",
              "  'eval_F1': 0.619774647881136,\n",
              "  'eval_Precision': 0.6210251579503554,\n",
              "  'eval_Recall': 0.6248301630434783,\n",
              "  'eval_Support': None,\n",
              "  'eval_loss': 1.1697031259536743,\n",
              "  'eval_runtime': 299.4057,\n",
              "  'eval_samples_per_second': 19.666,\n",
              "  'step': 2331},\n",
              " {'epoch': 10.0,\n",
              "  'learning_rate': 4.273504273504274e-09,\n",
              "  'loss': 0.2761,\n",
              "  'step': 2590},\n",
              " {'epoch': 10.0,\n",
              "  'step': 2590,\n",
              "  'train_Accuracy': 0.9153852346831978,\n",
              "  'train_F1': 0.9152689630961366,\n",
              "  'train_Precision': 0.915354608678587,\n",
              "  'train_Recall': 0.9153852346831978,\n",
              "  'train_Support': None,\n",
              "  'train_loss': 0.20590989291667938,\n",
              "  'train_runtime': 299.1496,\n",
              "  'train_samples_per_second': 83.042},\n",
              " {'epoch': 10.0,\n",
              "  'eval_Accuracy': 0.6260190217391305,\n",
              "  'eval_F1': 0.6205632714678547,\n",
              "  'eval_Precision': 0.6228340276253566,\n",
              "  'eval_Recall': 0.6260190217391305,\n",
              "  'eval_Support': None,\n",
              "  'eval_loss': 1.1924821138381958,\n",
              "  'eval_runtime': 299.1518,\n",
              "  'eval_samples_per_second': 19.682,\n",
              "  'step': 2590},\n",
              " {'epoch': 10.0,\n",
              "  'step': 2590,\n",
              "  'total_flos': 1698368086882800.0,\n",
              "  'train_runtime': 10702.8138,\n",
              "  'train_samples_per_second': 0.242}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY3rUW0HGrzq"
      },
      "source": [
        "## Plotting training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM4T7EOLGtP5",
        "outputId": "a1e762b2-f516-4c3c-9415-2728edd2584f"
      },
      "source": [
        "for log_history in trainer.state.log_history:\n",
        "  print(log_history.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'learning_rate', 'epoch', 'step'])\n",
            "dict_keys(['train_loss', 'train_Accuracy', 'train_F1', 'train_Precision', 'train_Recall', 'train_Support', 'train_runtime', 'train_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['eval_loss', 'eval_Accuracy', 'eval_F1', 'eval_Precision', 'eval_Recall', 'eval_Support', 'eval_runtime', 'eval_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['loss', 'learning_rate', 'epoch', 'step'])\n",
            "dict_keys(['train_loss', 'train_Accuracy', 'train_F1', 'train_Precision', 'train_Recall', 'train_Support', 'train_runtime', 'train_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['eval_loss', 'eval_Accuracy', 'eval_F1', 'eval_Precision', 'eval_Recall', 'eval_Support', 'eval_runtime', 'eval_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['loss', 'learning_rate', 'epoch', 'step'])\n",
            "dict_keys(['train_loss', 'train_Accuracy', 'train_F1', 'train_Precision', 'train_Recall', 'train_Support', 'train_runtime', 'train_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['eval_loss', 'eval_Accuracy', 'eval_F1', 'eval_Precision', 'eval_Recall', 'eval_Support', 'eval_runtime', 'eval_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['loss', 'learning_rate', 'epoch', 'step'])\n",
            "dict_keys(['train_loss', 'train_Accuracy', 'train_F1', 'train_Precision', 'train_Recall', 'train_Support', 'train_runtime', 'train_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['eval_loss', 'eval_Accuracy', 'eval_F1', 'eval_Precision', 'eval_Recall', 'eval_Support', 'eval_runtime', 'eval_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['loss', 'learning_rate', 'epoch', 'step'])\n",
            "dict_keys(['train_loss', 'train_Accuracy', 'train_F1', 'train_Precision', 'train_Recall', 'train_Support', 'train_runtime', 'train_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['eval_loss', 'eval_Accuracy', 'eval_F1', 'eval_Precision', 'eval_Recall', 'eval_Support', 'eval_runtime', 'eval_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['loss', 'learning_rate', 'epoch', 'step'])\n",
            "dict_keys(['train_loss', 'train_Accuracy', 'train_F1', 'train_Precision', 'train_Recall', 'train_Support', 'train_runtime', 'train_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['eval_loss', 'eval_Accuracy', 'eval_F1', 'eval_Precision', 'eval_Recall', 'eval_Support', 'eval_runtime', 'eval_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['loss', 'learning_rate', 'epoch', 'step'])\n",
            "dict_keys(['train_loss', 'train_Accuracy', 'train_F1', 'train_Precision', 'train_Recall', 'train_Support', 'train_runtime', 'train_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['eval_loss', 'eval_Accuracy', 'eval_F1', 'eval_Precision', 'eval_Recall', 'eval_Support', 'eval_runtime', 'eval_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['loss', 'learning_rate', 'epoch', 'step'])\n",
            "dict_keys(['train_loss', 'train_Accuracy', 'train_F1', 'train_Precision', 'train_Recall', 'train_Support', 'train_runtime', 'train_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['eval_loss', 'eval_Accuracy', 'eval_F1', 'eval_Precision', 'eval_Recall', 'eval_Support', 'eval_runtime', 'eval_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['loss', 'learning_rate', 'epoch', 'step'])\n",
            "dict_keys(['train_loss', 'train_Accuracy', 'train_F1', 'train_Precision', 'train_Recall', 'train_Support', 'train_runtime', 'train_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['eval_loss', 'eval_Accuracy', 'eval_F1', 'eval_Precision', 'eval_Recall', 'eval_Support', 'eval_runtime', 'eval_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['loss', 'learning_rate', 'epoch', 'step'])\n",
            "dict_keys(['train_loss', 'train_Accuracy', 'train_F1', 'train_Precision', 'train_Recall', 'train_Support', 'train_runtime', 'train_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['eval_loss', 'eval_Accuracy', 'eval_F1', 'eval_Precision', 'eval_Recall', 'eval_Support', 'eval_runtime', 'eval_samples_per_second', 'epoch', 'step'])\n",
            "dict_keys(['train_runtime', 'train_samples_per_second', 'total_flos', 'epoch', 'step'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "xjW01aT3GuvN",
        "outputId": "ef19d3d4-2c3f-4a11-ec58-72803aa53d6d"
      },
      "source": [
        "sns.set_style('darkgrid')\n",
        "train_loss = []\n",
        "eval_loss = []\n",
        "eval_acc = []\n",
        "train_acc = []\n",
        "\n",
        "for log_history in trainer.state.log_history:\n",
        "\n",
        "  if 'train_loss' in log_history.keys():\n",
        "    train_loss.append(log_history['train_loss'])\n",
        "    train_acc.append(log_history['train_Accuracy'])\n",
        "    \n",
        "  elif 'eval_loss' in log_history.keys():\n",
        "    eval_loss.append(log_history['eval_loss'])\n",
        "    eval_acc.append(log_history['eval_Accuracy'])\n",
        "\n",
        "x = range(1, len(train_acc) + 1)\n",
        "plt.figure(figsize = (12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(x, train_acc, 'b', label = 'Training accuracy')\n",
        "plt.plot(x, eval_acc, 'r', label = 'Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(x, train_loss, 'b', label = 'Training loss')\n",
        "plt.plot(x, eval_loss, 'r', label = 'Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbfd57d8510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPMROhZ_HGKj",
        "outputId": "135c073c-1a4c-410c-8ec1-704698d30b44"
      },
      "source": [
        "print(eval_loss, eval_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0654839277267456, 1.0757845640182495, 0.9960682988166809, 0.9887093305587769, 1.038999319076538, 1.0990045070648193, 1.1249126195907593, 1.1334296464920044, 1.1697031259536743, 1.1924821138381958] [0.4594089673913043, 0.505264945652174, 0.5706521739130435, 0.5922214673913043, 0.6056385869565217, 0.6098845108695652, 0.618546195652174, 0.6200747282608695, 0.6248301630434783, 0.6260190217391305]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "yMC6nmwAYoX-",
        "outputId": "c7b3292c-6736-419c-bac9-bd3378bbad99"
      },
      "source": [
        "trainer.predict(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='409' max='409' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [409/409 02:10]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(array([0.55444423, 0.61829475, 0.53708958]), array([0.57506361, 0.6792804 , 0.42278239]), array([0.56456572, 0.64735442, 0.4731298 ]), array([5109, 4836, 3134]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[ 1.1682962 ,  1.8538942 , -2.420154  ],\n",
              "       [ 1.6199521 ,  1.3385397 , -2.4182038 ],\n",
              "       [-2.1470115 ,  3.0189173 , -1.3297758 ],\n",
              "       ...,\n",
              "       [ 2.1409113 , -2.7389429 ,  0.82145435],\n",
              "       [ 1.9699595 , -2.33028   ,  0.6156627 ],\n",
              "       [ 3.1488488 , -2.4010017 , -0.01001421]], dtype=float32), label_ids=array([1, 1, 1, ..., 2, 2, 2]), metrics={'test_loss': 1.4325487613677979, 'test_Accuracy': 0.5771083416163315, 'test_F1': 0.5732671469893497, 'test_Precision': 0.573894621283847, 'test_Recall': 0.5771083416163315, 'test_Support': None, 'test_runtime': 131.1943, 'test_samples_per_second': 99.692, 'test_mem_cpu_alloc_delta': 413696, 'test_mem_gpu_alloc_delta': 0, 'test_mem_cpu_peaked_delta': 0, 'test_mem_gpu_peaked_delta': 799074304})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLQ5pfZWLT7g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}